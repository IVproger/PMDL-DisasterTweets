{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9705871,"sourceType":"datasetVersion","datasetId":5936044}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence_transformers\n!pip install peft\n!pip install demoji\n!pip install spacy\n!pip install scikit-learn\n!python -m spacy download en_core_web_sm","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:07:12.209754Z","iopub.execute_input":"2024-11-01T06:07:12.210351Z","iopub.status.idle":"2024-11-01T06:08:39.192313Z","shell.execute_reply.started":"2024-11-01T06:07:12.210315Z","shell.execute_reply":"2024-11-01T06:08:39.191337Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.2.1\nCollecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.2\nCollecting demoji\n  Downloading demoji-1.1.0-py3-none-any.whl.metadata (9.2 kB)\nDownloading demoji-1.1.0-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: demoji\nSuccessfully installed demoji-1.1.0\nRequirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.9.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (70.0.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.4.1)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (70.0.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.corpus import stopwords\nfrom sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport re\\\nimport torch\nimport demoji\nimport spacy\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# --- Download resources only once at the top-level ---\n\n# Ensure that necessary NLTK and demoji resources are available\nnlp = spacy.load('en_core_web_sm') # Lemmatization, Tokenizer and Stopwords\nif not demoji.last_downloaded_timestamp():\n    demoji.download_codes()  # Only download codes once, skip if already done\n\n# --- Feature Extractor Transformer ---\n\nclass feature_extractor(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Extracts specific columns from a DataFrame.\n\n    Args:\n        features: List of feature names to extract from the DataFrame.\n    \"\"\"\n    def __init__(self, features: list[str]):\n        self.features = features\n\n    def fit(self, X, y=None):\n        return self  # No fitting required\n\n    def transform(self, X):\n        # Keep only the specified columns\n        existing_features = [feature for feature in self.features if feature in X.columns]\n        X_transformed = X[existing_features].copy()\n        return X_transformed\n\n\n# --- Clear Columns Transformer ---\nclass clear_columns(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Cleans the specified text columns in a DataFrame by applying several cleaning steps:\n    - Removes non-alphabetic characters.\n    - Removes short words (less than 3 characters).\n    - Removes URLs.\n    - Replaces emoji with descriptive text.\n    - Removes special characters like hashtags and HTML tags.\n    - Applies stemming and removes stopwords.\n\n    Args:\n        features: List of features to clean.\n    \"\"\"\n    def __init__(self, features):\n        self.features = features\n\n    def fit(self, X, y=None):\n        return self  # No fitting required\n\n    def transform(self, data):\n        # Apply cleaning to each feature in the list\n        for feature in self.features:\n            if feature in data.columns:\n                data[feature] = data[feature].apply(self.clean_text)\n        return data\n\n    def clean_text(self, text):\n        \"\"\"Cleans a single text entry using multiple regex and NLP techniques.\"\"\"\n        if pd.isnull(text):\n            return text  # Return if null value\n\n        text = str(text).lower()\n        text = demoji.replace_with_desc(text)\n        text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%|\\-)*\\b', 'url', text)\n        text = re.sub(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', 'html', text)\n        text = re.sub(' +', ' ', text).strip()\n        text = ' '.join([token.lemma_ for token in nlp(text) if not token.is_stop])\n\n        return text.strip()\n\n\n# --- Merge Columns Transformer ---\nclass merge_columns(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Merges multiple text columns into one, with an option to drop the original columns.\n\n    Args:\n        features: List of features to merge.\n        new_feature_name: The name of the new merged column.\n        drop_original: If True, drops the original columns after merging unless the new column name matches one of the old ones.\n    \"\"\"\n    def __init__(self, features, new_feature_name='merged_text', drop_original=True):\n        self.features = features\n        self.new_feature_name = new_feature_name\n        self.drop_original = drop_original\n\n    def fit(self, X, y=None):\n        return self  # No fitting required\n\n    def transform(self, X):\n        # Merge the columns into one\n        X[self.new_feature_name] = X[self.features].apply(self.merge_text, axis=1)\n\n        # Drop original columns if requested, except if the new feature name matches one of the originals\n        if self.drop_original:\n            features_to_drop = [f for f in self.features if f != self.new_feature_name]\n            if features_to_drop:\n                X = X.drop(columns=features_to_drop)\n\n        return X\n\n    def merge_text(self, row):\n        \"\"\"Merges the content of the specified columns into a single string.\"\"\"\n        return (' '.join([str(row[feature]) for feature in self.features if pd.notnull(row[feature])])).strip()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:29.360188Z","iopub.execute_input":"2024-10-29T12:57:29.360522Z","iopub.status.idle":"2024-10-29T12:57:50.412198Z","shell.execute_reply.started":"2024-10-29T12:57:29.360487Z","shell.execute_reply":"2024-10-29T12:57:50.411154Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel_name = 'microsoft/deberta-v3-large'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_datastore() -> tuple[pd.DataFrame, pd.DataFrame, str]:\n    \"\"\"\n    Read the sample data.\n    \"\"\"\n    \n    train_path = '/kaggle/input/dataset/train.csv' # другой путь, в kaggle делал\n    test_path = '/kaggle/input/dataset/test.csv'   # другой путь, в kaggle делал\n\n    train_data = pd.read_csv(train_path)\n    test_data = pd.read_csv(test_path)\n    \n    return train_data, test_data\n\ndef tokenize_dataset(dataset):\n    return tokenizer(dataset['text'])","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:58.264776Z","iopub.execute_input":"2024-10-29T12:57:58.265094Z","iopub.status.idle":"2024-10-29T12:57:58.270627Z","shell.execute_reply.started":"2024-10-29T12:57:58.265059Z","shell.execute_reply":"2024-10-29T12:57:58.269760Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = read_datastore()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:58.271805Z","iopub.execute_input":"2024-10-29T12:57:58.272198Z","iopub.status.idle":"2024-10-29T12:57:58.385322Z","shell.execute_reply.started":"2024-10-29T12:57:58.272151Z","shell.execute_reply":"2024-10-29T12:57:58.384447Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:58.386595Z","iopub.execute_input":"2024-10-29T12:57:58.386900Z","iopub.status.idle":"2024-10-29T12:57:58.408114Z","shell.execute_reply.started":"2024-10-29T12:57:58.386867Z","shell.execute_reply":"2024-10-29T12:57:58.407189Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         id keyword location  \\\n0         1     NaN      NaN   \n1         4     NaN      NaN   \n2         5     NaN      NaN   \n3         6     NaN      NaN   \n4         7     NaN      NaN   \n...     ...     ...      ...   \n7608  10869     NaN      NaN   \n7609  10870     NaN      NaN   \n7610  10871     NaN      NaN   \n7611  10872     NaN      NaN   \n7612  10873     NaN      NaN   \n\n                                                   text  target  \n0     Our Deeds are the Reason of this #earthquake M...       1  \n1                Forest fire near La Ronge Sask. Canada       1  \n2     All residents asked to 'shelter in place' are ...       1  \n3     13,000 people receive #wildfires evacuation or...       1  \n4     Just got sent this photo from Ruby #Alaska as ...       1  \n...                                                 ...     ...  \n7608  Two giant cranes holding a bridge collapse int...       1  \n7609  @aria_ahrary @TheTawniest The out of control w...       1  \n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n7611  Police investigating after an e-bike collided ...       1  \n7612  The Latest: More Homes Razed by Northern Calif...       1  \n\n[7613 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming df is your DataFrame and you want to apply transformations to all columns\nall_features = df_train.columns.tolist()[:-1]\nnew_feature_name = 'merged_text'\n\n# Create the pipeline\npipeline = Pipeline([\n    ('feature_extractor', feature_extractor(features=['text', 'target'])),\n#     ('clean_columns', clear_columns(features=['text'])),\n])\n\n# Example usage with a DataFrame `df`\ntransformed_df = pipeline.fit_transform(df_train)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:58.409262Z","iopub.execute_input":"2024-10-29T12:57:58.409789Z","iopub.status.idle":"2024-10-29T12:57:58.418234Z","shell.execute_reply.started":"2024-10-29T12:57:58.409754Z","shell.execute_reply":"2024-10-29T12:57:58.417392Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"transformed_df","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:58.419677Z","iopub.execute_input":"2024-10-29T12:57:58.420186Z","iopub.status.idle":"2024-10-29T12:57:58.433239Z","shell.execute_reply.started":"2024-10-29T12:57:58.420143Z","shell.execute_reply":"2024-10-29T12:57:58.432366Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                   text  target\n0     Our Deeds are the Reason of this #earthquake M...       1\n1                Forest fire near La Ronge Sask. Canada       1\n2     All residents asked to 'shelter in place' are ...       1\n3     13,000 people receive #wildfires evacuation or...       1\n4     Just got sent this photo from Ruby #Alaska as ...       1\n...                                                 ...     ...\n7608  Two giant cranes holding a bridge collapse int...       1\n7609  @aria_ahrary @TheTawniest The out of control w...       1\n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n7611  Police investigating after an e-bike collided ...       1\n7612  The Latest: More Homes Razed by Northern Calif...       1\n\n[7613 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import datasets\n\ntrain_dataset = datasets.Dataset.from_pandas(transformed_df)\ndataset = datasets.DatasetDict({\n    \"train\": train_dataset\n})\n\ndataset = dataset.rename_column('target', 'label')\ndataset = dataset.cast_column('label', datasets.ClassLabel(num_classes=2, names=['negative', 'positive']))\ndataset = dataset.map(tokenize_dataset, batched=True)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:58.434185Z","iopub.execute_input":"2024-10-29T12:57:58.434485Z","iopub.status.idle":"2024-10-29T12:57:59.088301Z","shell.execute_reply.started":"2024-10-29T12:57:58.434454Z","shell.execute_reply":"2024-10-29T12:57:59.087313Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/7613 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2cd1bcead8d46179682e34241aeca00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7613 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209f633c22704c57bd5fcaef736edc8b"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 7613\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support\n\ndef compute_metrics(p):\n    y_true = p.label_ids\n    y_pred = p.predictions.argmax(axis=1)\n    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average='binary')\n    return {'precision': precision, 'recall': recall, 'f1': f1}","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:59.091940Z","iopub.execute_input":"2024-10-29T12:57:59.092251Z","iopub.status.idle":"2024-10-29T12:57:59.097775Z","shell.execute_reply.started":"2024-10-29T12:57:59.092218Z","shell.execute_reply":"2024-10-29T12:57:59.096797Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset, DatasetDict\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:59.098990Z","iopub.execute_input":"2024-10-29T12:57:59.099935Z","iopub.status.idle":"2024-10-29T12:57:59.111034Z","shell.execute_reply.started":"2024-10-29T12:57:59.099883Z","shell.execute_reply":"2024-10-29T12:57:59.110092Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nwandb.login(key='2b54d6ba06d99adb32b2f4b8e5061a6fb40be4a0')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:57:59.112159Z","iopub.execute_input":"2024-10-29T12:57:59.112495Z","iopub.status.idle":"2024-10-29T12:58:01.252453Z","shell.execute_reply.started":"2024-10-29T12:57:59.112450Z","shell.execute_reply":"2024-10-29T12:58:01.251556Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"## Training arguments\ntraining_args = TrainingArguments(\n    report_to='none',\n    output_dir='./results',\n    evaluation_strategy='no',\n    save_strategy='no',\n    logging_strategy='steps',\n    logging_steps=10,\n    fp16=True,\n    learning_rate=2e-5,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=8,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    warmup_ratio=0.1,\n    eval_steps=16,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_args,\n    train_dataset=dataset['train'],\n    eval_dataset=None,\n    compute_metrics=compute_metrics,\n)\n\n# Train the model\ntrainer.train()\n\nmodel.save_pretrained(\"./models/first_lora\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T12:58:01.254191Z","iopub.execute_input":"2024-10-29T12:58:01.255404Z","iopub.status.idle":"2024-10-29T14:09:47.944049Z","shell.execute_reply.started":"2024-10-29T12:58:01.255337Z","shell.execute_reply":"2024-10-29T14:09:47.943019Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='950' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [950/950 1:11:34, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.698800</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.700000</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.672500</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.666900</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.603700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.650200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.665700</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.625100</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.552600</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.470600</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.544700</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.424900</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.431200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.398000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.595200</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.519600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.438700</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.416900</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.474400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.484300</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.498400</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.365400</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.435800</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.354000</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.472500</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.539200</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.485800</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.442200</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.359100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.479800</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.450400</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.428900</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.480500</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.460700</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.440900</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.505600</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.549400</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.483800</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.414300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.410100</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.489000</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.448900</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.430800</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.452700</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.409600</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.440400</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.437400</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.418800</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.411600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.474300</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.407800</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.398300</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.417500</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.316000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.349900</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.368700</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.279100</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.393700</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.363600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.406800</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.496900</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.394100</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.364500</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.413600</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.383100</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.383900</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.396600</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.315600</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.369200</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.317200</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.385600</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.345900</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.383700</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.357100</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.352800</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.339000</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.413700</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.376100</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.432300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.380400</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.340800</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.353500</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.293100</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.377200</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.292100</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.284300</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.223800</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.368000</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.309600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.394000</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.411100</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.382100</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.368400</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.326300</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.374600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"# Create the pipeline\npipeline = Pipeline([\n    ('feature_extractor', feature_extractor(features=['id', 'text'])),\n#     ('merge_columns', merge_columns(features=['location', 'text'], new_feature_name='text')),\n#     ('clean_columns', clear_columns(features=['text'])),\n])\n\ntransformed_df_test = pipeline.fit_transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:09:47.945563Z","iopub.execute_input":"2024-10-29T14:09:47.946308Z","iopub.status.idle":"2024-10-29T14:09:47.953111Z","shell.execute_reply.started":"2024-10-29T14:09:47.946261Z","shell.execute_reply":"2024-10-29T14:09:47.952085Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"transformed_df_test['id']","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:09:47.954268Z","iopub.execute_input":"2024-10-29T14:09:47.954573Z","iopub.status.idle":"2024-10-29T14:09:47.967287Z","shell.execute_reply.started":"2024-10-29T14:09:47.954542Z","shell.execute_reply":"2024-10-29T14:09:47.966419Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0           0\n1           2\n2           3\n3           9\n4          11\n        ...  \n3258    10861\n3259    10865\n3260    10868\n3261    10874\n3262    10875\nName: id, Length: 3263, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset = datasets.Dataset.from_pandas(transformed_df_test)\ndataset_test = datasets.DatasetDict({\n    \"test\": test_dataset\n})\n\n\ndataset_test = dataset_test.map(tokenize_dataset, batched=True)\n\npredictions, _, _ = trainer.predict(dataset_test['test'])\n\nsubmission_df = pd.DataFrame({\n    'id': dataset_test['test']['id'],\n    'target': predictions.argmax(axis=1)\n})\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:09:47.968522Z","iopub.execute_input":"2024-10-29T14:09:47.968850Z","iopub.status.idle":"2024-10-29T14:16:42.166363Z","shell.execute_reply.started":"2024-10-29T14:09:47.968797Z","shell.execute_reply":"2024-10-29T14:16:42.165612Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3263 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1f87f4f509d4cdea7fafce1101ab939"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:16:42.167571Z","iopub.execute_input":"2024-10-29T14:16:42.167966Z","iopub.status.idle":"2024-10-29T14:16:42.178109Z","shell.execute_reply.started":"2024-10-29T14:16:42.167921Z","shell.execute_reply":"2024-10-29T14:16:42.177239Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"         id  target\n0         0       1\n1         2       1\n2         3       1\n3         9       1\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       1\n3261  10874       1\n3262  10875       1\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# model.save_pretrained(\"./new_models1/model\")\n# tokenizer.save_pretrained(\"./new_tokenizer1/tokenizer\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}